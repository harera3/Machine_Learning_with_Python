{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAPTER 11\n",
    "---\n",
    "# MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- In this chapter we will examine strategies for evaluating the quality of models created through our learning algorithms. \n",
    "- It might appear strange to discuss model evaluation before discussing how to create them, but there is a method to our madness. \n",
    "- Models are only as useful as the quality of their predictions, and thus fundamentally our goal is not to create models (which is easy) but to create high-quality models (which is hard). \n",
    "- Therefore, before we explore the myriad learning algorithms, we first set up how we can evaluate the models they produce.\n",
    "\n",
    "## 11.1 Cross-Validating Models\n",
    "**Problem:** we want to evaluate how well our model will work in the real world\n",
    "\n",
    "**Solution:** we will create a pipeline that\n",
    "- preprocesses the data, \n",
    "- trains the model, and then \n",
    "- evaluates it using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9693916821849783"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# create features matrix\n",
    "features = digits.data\n",
    "\n",
    "# create target vector\n",
    "target = digits.target\n",
    "\n",
    "# create standardizer\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# create logitic regression object\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# create a pipeline that standardizes, then runs logistic regression\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "\n",
    "# create k-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# conduct k-fold cross-validation\n",
    "cv_results = cross_val_score(pipeline, # Pipeline\n",
    "                             features, # feature matrix\n",
    "                             target, # target vector\n",
    "                             cv=kf, # cross-validation technique,\n",
    "                             scoring=\"accuracy\", # loss function\n",
    "                             n_jobs=-1) # use all CPU cores\n",
    "\n",
    "# calculate mean\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "- Our goal is to evaluate how well our model does on data it has never seen before (e.g., a new customer, a new crime, a new image). \n",
    "- **The validation approach:**\n",
    "    - split data into training set and test set\n",
    "    - set the test set aside and pretend it's never been seen before\n",
    "    - train the model on the training set and teach it how to make the best predictions\n",
    "    - evaluate the model on the testing set and see how it does\n",
    "- The two major weaknesses of the validation approach:\n",
    "    - the performance of the model can be highly dependent on which few observations were selected for the test set. \n",
    "    - Second, the model is not being trained using all the available data, and not being evaluated on all the available data.\n",
    "- **The k-fold cross-validation (KFCV) strategy:**\n",
    "    - data is split into k parts, called \"*folds*\"\n",
    "    - the model is trained using k-1 folds, combined as a training set\n",
    "    - the last fold is used as a test set\n",
    "    - this is repeated k times each time using a different fold as the test set. \n",
    "    - The performance on the model for each of the k iterations is then averaged to produce an overall measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.98888889, 0.96111111, 0.94444444, 0.97777778,\n",
       "       0.98333333, 0.95555556, 0.98882682, 0.97765363, 0.93854749])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KFCV assumes that each observation was created independent from the other, if so it is a good idea to shuffle observations which can be done in scikit-learn by setting shuffle=True.\n",
    "- When using KFCV to evaluate a classifier, it is often beneficial to perform *stratified k-fold* by replacing KFold class with StratifiedKFold. \n",
    "- When using validation sets or cross-validation, it is important to preprocess data based on the training set and then apply those transformations to both the training and test set. The reason is\n",
    "    - we are pretending that the test set is unknown data\n",
    "    - it prevents the leaking of information from test set into the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.98888889, 0.96111111, 0.94444444, 0.97777778,\n",
       "       0.98333333, 0.95555556, 0.98882682, 0.97765363, 0.93854749])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# Fit standardizer to training set\n",
    "standardizer.fit(features_train)\n",
    "\n",
    "# Apply to both training and test sets\n",
    "features_train_std = standardizer.transform(features_train)\n",
    "features_test_std = standardizer.transform(features_test)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "\n",
    "# Do k-fold cross-validation\n",
    "cv_results = cross_val_score(pipeline, # Pipeline\n",
    "                             features, # Feature matrix\n",
    "                             target, # Target vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring=\"accuracy\", # Loss function\n",
    "                             n_jobs=-1) # Use all CPU scores\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross_val_score parameters:\n",
    "- cv determines our cross-validation technique. K-fold is the most common by far\n",
    "- the scoring parameter defines our metric for success\n",
    "- n_jobs=-1 tells scikit-learn to use every core of the computer available to speed up the operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Creating a Baseline Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** we want a simple baseline regression model to compare against our model.\n",
    "\n",
    "**Solution:** use scikit-learnâ€™s DummyRegressor to create a simple model to use as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.001119359203955339"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "boston = load_boston()\n",
    "\n",
    "# Create features\n",
    "features, target = boston.data, boston.target\n",
    "\n",
    "# Make test and training split\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, random_state=0)\n",
    "\n",
    "# Create a dummy regressor\n",
    "dummy = DummyRegressor(strategy='mean')\n",
    "\n",
    "# \"Train\" dummy regressor\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "# Get R-squared score\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare, we train our model and evaluate the performance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6354638433202129"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train simple linear regression model\n",
    "ols = LinearRegression()\n",
    "ols.fit(features_train, target_train)\n",
    "\n",
    "# Get R-squared score\n",
    "ols.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 Creating a Baseline Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** You want a simple baseline classifier to compare against your model.\n",
    "\n",
    "**Solution:** Use scikit-learnâ€™s DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42105263157894735"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "\n",
    "# Create target vector and feature matrix\n",
    "features, target = iris.data, iris.target\n",
    "\n",
    "# Split into training and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "features, target, random_state=0)\n",
    "\n",
    "# Create dummy classifier\n",
    "dummy = DummyClassifier(strategy='uniform', random_state=1)\n",
    "\n",
    "# \"Train\" model\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "# Get accuracy score\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the baseline classifier to our trained classifier, we can see the improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Train model\n",
    "classifier.fit(features_train, target_train)\n",
    "\n",
    "# Get accuracy score\n",
    "classifier.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A common measure of a classifierâ€™s performance is how much better it is than random guessing. scikit-learnâ€™s DummyClassifier makes this comparison easy. \n",
    "- The strategy parameter gives us a number of options for generating values. There are two strategies. \n",
    "    - *stratified* makes predictions that are proportional to the training setâ€™s target vectorâ€™s class proportions \n",
    "    - *uniform* will generate predictions uniformly at random between the different classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 Evaluating Binary Classifier Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Given a trained classification model, you want to evaluate its quality.\n",
    "\n",
    "**Solution:** Use scikit-learnâ€™s cross_val_score to conduct cross-validation while using the scoring parameter to define one of a number of performance metrics, including accuracy, precision, recall, and F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9555, 0.95  , 0.9585, 0.9555, 0.956 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# generate features matrix and target vector\n",
    "X, y = make_classification(n_samples = 10000,\n",
    "                           n_features = 3,\n",
    "                           n_informative = 3,\n",
    "                           n_redundant = 0,\n",
    "                           n_classes = 2,\n",
    "                           random_state = 1)\n",
    "# create logistic regression\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# cross-validate model using accuracy\n",
    "cross_val_score(logit, X, y, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95963673, 0.94820717, 0.9635996 , 0.96149949, 0.96060606])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using precision\n",
    "cross_val_score(logit, X, y, scoring=\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.951, 0.952, 0.953, 0.949, 0.951])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using recall\n",
    "cross_val_score(logit, X, y, scoring=\"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95529884, 0.9500998 , 0.95827049, 0.95520886, 0.95577889])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using f1\n",
    "cross_val_score(logit, X, y, scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can measure accuracy in 5-fold (the default number of folds) cross-validation by setting scoring=\"accuracy\"\n",
    "- Models with high precision are pessimistic in that they only predict an observation is of the positive class when they are very certain about it.\n",
    "- Models with high recall are optimistic in that they have a low bar for predicting that an observation is in the positive class\n",
    "- The F1 score is the harmonic mean (a kind of average used for ratios). It is a measure of correctness achieved in positive predictionâ€”that is, of observations labeled as positive, how many are actually positive.\n",
    "\n",
    "Alternatively to using cross_val_score, if we already have the true y values and the predicted y values, we can calculate metrics like accuracy and recall directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.947"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create training and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "# Predict values for training target vector\n",
    "y_hat = logit.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5 Evaluating Binary Classifier Thresholds\n",
    "\n",
    "**Problem:** You want to evaluate a binary classifier and various probability thresholds.\n",
    "\n",
    "**Solution:** The Receiving Operating Characteristic (ROC) curve is a common method for evaluating the quality of a binary classifier. \n",
    "\n",
    "In scikit-learn, we can use roc_curve to calculate the true and false positives at each threshold, then plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# load libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create feature matrix and target vector\n",
    "features, target = make_classification(n_samples=10000,\n",
    "                                       n_features=10,\n",
    "                                       n_classes=2,\n",
    "                                       n_informative=3,\n",
    "                                       random_state=3)\n",
    "# split into training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=1)\n",
    "\n",
    "# create classifier\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# train model\n",
    "logit.fit(features_train, target_train)\n",
    "\n",
    "# get predicted probabilities\n",
    "target_probabilities = logit.predict_proba(features_test)[:,1]\n",
    "\n",
    "# create true and positive rates\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(target_test, target_probabilities)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.title(\"Reciever Operating Characteristic\")\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1,0], c=\".7\") \n",
    "plt.plot([1, 1], c=\".7\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROC compares the presence of true positives and false positives at every probability threshold (i.e., the probability at which an observation is predicted to be a class). \n",
    "- By plotting the ROC curve, we can see how the model performs. \n",
    "    - A classifier that predicts every observation correctly would look like the solid light gray line in the chart above, going straight up to the top immediately. \n",
    "    - A classifier that predicts at random will appear as the diagonal line. \n",
    "    - The better the model, the closer it is to the solid line.     \n",
    "\n",
    "#### Discussion:\n",
    "- Up until now we have only examined models based on the values they predict. \n",
    "- However, in many learning algorithms those predicted values are based off of probability estimates. \n",
    "- In our solution, we can use predict_proba to see the predicted probabilities for the first observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87094106, 0.12905894]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predicted probabilities\n",
    "logit.predict_proba(features_test)[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see the probability classes\n",
    "logit.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the first observation has an ~87% chance of being in the negative class (0) and a 13% chance of being in the positive class (1)\n",
    "\n",
    "**Threshold:** By default, scikit-learn predicts an observation is part of the positive class if the probability is greater than 0.5\n",
    "- However, instead of a middle ground, we will often want to explicitly bias our model to use a different threshold for substantive reasons: false positive or false negative, which one to avoid the most?\n",
    "- The prediction trade-off is represented by the true positive rate (TPR) and the false positive rate (FPR)\n",
    "- The ROC curve represents the respective TPR and FPR for every probability threshold. \n",
    "- Let's examine the threshold values and see what happens to TPR and FPR when we change the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52006024, 0.51901229, 0.51469154, 0.51464729, 0.51192875,\n",
       "       0.50977873, 0.50556537, 0.50265506, 0.50208102, 0.5016343 ,\n",
       "       0.50068825, 0.49922991, 0.49273392, 0.49237501, 0.49226661,\n",
       "       0.49224401, 0.49221264, 0.4882918 , 0.484656  , 0.48362505])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from Innocent, not in book\n",
    "threshold[240:260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2d5e5cd8bc8>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from Innocent, not in book\n",
    "# excluding the first value, which is 2\n",
    "plt.plot(threshold[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our solution a threshold of roughly 0.50 has a TPR of ~0.84 and an FPR of ~0.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5006882519902771\n",
      "True Positive Rate: 0.839518555667001\n",
      "False Positive Rate: 0.1744765702891326\n"
     ]
    }
   ],
   "source": [
    "print(\"Threshold: {}\".format(threshold[250]))\n",
    "print(\"True Positive Rate: {}\".format(true_positive_rate[250]))\n",
    "print(\"False Positive Rate: {}\".format(false_positive_rate[250]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we increase the threshold to ~80% (i.e., increase how certain the model has to be before it predicts an observation as positive) the TPR drops significantly but so does the FPR. This is because our higher requirement for being predicted to be in the positive class has made the model not identify a number of positive observations (the lower TPR), but also reduce the noise from negative observations being predicted as positive (the lower FPR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.8043803686853731\n",
      "True Positive Rate: 0.567703109327984\n",
      "False Positive Rate: 0.05284147557328016\n"
     ]
    }
   ],
   "source": [
    "print(\"Threshold: {}\".format(threshold[95]))\n",
    "print(\"True Positive Rate: {}\".format(true_positive_rate[95]))\n",
    "print(\"False Positive Rate: {}\".format(false_positive_rate[95]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often common to calculate the area under the ROC curve (AUCROC) to judge the overall quality of a model at all possible thresholds. The better a model is, the higher the curve and thus the greater the area under the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9060171541543875"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate area under curve\n",
    "roc_auc_score(target_test, target_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.6 Evaluating Multiclass Classifier Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** You have a model that predicts three or more classes and want to evaluate its performance.\n",
    "\n",
    "**Solution:** Use cross-validation with an evaluation metric capable of handling more than two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.841 , 0.829 , 0.8265, 0.8155, 0.82  ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# generate features matrix and target vector\n",
    "features, target = make_classification(n_samples=10000,\n",
    "                                       n_features=3,\n",
    "                                       n_informative=3,\n",
    "                                       n_redundant=0,\n",
    "                                       n_classes=3,\n",
    "                                       random_state=1)\n",
    "# create logistic regression\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# cross-validate model using accuracy\n",
    "cross_val_score(logit, features, target, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion:\n",
    "- When we have balanced classes (e.g. a roughly equal number of observations in each class of a target vector), accuracy is--just like in the binary class setting--a simple and interpretable choce for an evaluation metric. \n",
    "    - Accuracy is the number of correct predictions divided by the number of observations and works just as well in the multiclass as binary setting. \n",
    "- However, when we have imbalanced classes (a common scenario), we should be inclined to use other evaluation metrics.\n",
    "    - Precision, recall, and F1 scores are useful metrics. \n",
    "    - While all of them were originally designed for binary classifiers, we can apply them to multiclass settings by treating our data as a set of binary classes. \n",
    "    - Doing so enables us to apply the metrics to each class as if it were the only class in the data, and then aggregate the evaluation scores for all the classes by averaging them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84061272, 0.82895312, 0.82625661, 0.81515121, 0.81992692])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using macro averaged F1 score\n",
    "cross_val_score(logit, features, target, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods used to average the evaluation scores from the classes:\n",
    "- **macro:** Calculate mean of metric scores for each class, weighting each class equally.\n",
    "- **weighted:** Calculate mean of metric scores for each class, weighting each class proportional to its size in the data.\n",
    "- **micro:** Calculate mean of metric scores for each observation-class combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84063166, 0.8289688 , 0.82630601, 0.8151928 , 0.81998327])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using macro averaged F1 score\n",
    "cross_val_score(logit, features, target, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.841 , 0.829 , 0.8265, 0.8155, 0.82  ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using macro averaged F1 score\n",
    "cross_val_score(logit, features, target, scoring='f1_micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.7 Visualizing a Classifierâ€™s Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Given predicted classes and true classes of the test data, you want to visually compare the modelâ€™s quality.\n",
    "\n",
    "**Solution:** Use a confusion matrix, which compares predicted classes and true classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
