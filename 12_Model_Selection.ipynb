{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAPTER 12\n",
    "---\n",
    "# MODEL SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- Model selection is, in this book, selecting the best learning algorithm and its best hyperparameters\n",
    "- In this chapter, we will cover techniques to efficiently select the best model from a set of candidates\n",
    "- Hyperparameters are like the settings for the learning algorithm that we must choose before starting training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1 Selecting Best Models Using Exhaustive Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** You want to select the best model by searching over a range of hyperparameters\n",
    "\n",
    "**Solution:** Use scikit-learn’s GridSearchCV\n",
    "- GridSearchCV is a brute-force approach to model selection using cross-validation.\n",
    "- Specifically, a user defines sets of possible values for one or multiple hyperparameters, and then GridSearchCV trains a model using every value and/or combination of values. \n",
    "- The model with the best performance score is selected as the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l1\n",
      "Best C: 2.7825594022071245\n",
      "Best Solver: saga\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# Create logistic regression\n",
    "logistic = linear_model.LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Create range of candidate regularization values\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create range of candidate solver values\n",
    "l1_solver = ['liblinear', 'saga']\n",
    "l2_solver = ['newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "\n",
    "# Create dictionary hyperparameter candidates\n",
    "hyperparameters = [dict(C=C, penalty=['l1'], solver=l1_solver), \n",
    "                   dict(C=C, penalty=['l2'], solver=l2_solver)]\n",
    "\n",
    "# Create grid search\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = gridsearch.fit(features, target)\n",
    "\n",
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best Solver:', best_model.best_estimator_.get_params()['solver'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**My additions to book's code:**\n",
    "- The code, as it is written in the book, was throwing a bunch of errors (\"FitFailedWarning\") due to the fact that some hyperparameters cannot be combined. I wish skit-learn ignored them but it has to show errors\n",
    "- I added the solver values and modified the hyperparameters variable to separate l1 parameters from l2 parameters. \n",
    "- To my surprise it worked perfectly and I actually learned something new.\n",
    "- I also added max_iter=10000 in the logistic variable because I was getting ConvergenceWarning\n",
    "\n",
    "#### Discussion:\n",
    "- Let's calculate the number of models from which the best was selected:\n",
    "    - 10C * 1l1 * 2l1_solver = 20 models\n",
    "    - 10C * 1l2 * 4l2_solver = 40 models\n",
    "    - *Total:* 60 models\n",
    "- The best model's parameters are: solver=saga, penalty=l1, and C=2.78\n",
    "- By default, after identifying the best hyperparameters, GridSearchCV will retrain a model using the best hyperparameters on the entire dataset (rather than leaving a fold out for cross-validation). We can use this model to predict values like any other scikit-learn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict target vector\n",
    "best_model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.7825594022071245, max_iter=10000, penalty='l1',\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One GridSearchCV parameter is worth noting: verbose. While mostly unnecessary, it can be reassuring during long searching processes to receive an indication that the search is progressing. The verbose parameter determines the amount of messages\n",
    "outputted during the search, with 0 showing no output, and 1 to 3 outputting messages with increasing detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2 Selecting Best Models Using Randomized Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** You want a computationally cheaper method than exhaustive search to select the best model.\n",
    "\n",
    "**Solution:** Use scikit-learn’s RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
