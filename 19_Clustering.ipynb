{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAPTER 19\n",
    "---\n",
    "# CLUSTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The goal of clustering algorithms is to identify those latent groupings of observations, which if done well, allow us to predict the class of observations even without a target vector. There are many clustering algorithms and they have a wide variety of approaches to identifying the clusters in data. In this chapter, we will cover a selection of clustering algorithms using scikit-learn and how to use them in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.1 Clustering Using K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You want to group observations into k groups.\n",
    "- Use k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0,\n",
       "       2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "       0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "       0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)\n",
    "\n",
    "# Create k-mean object\n",
    "cluster = KMeans(n_clusters=3, random_state=0)\n",
    "\n",
    "# Train model\n",
    "model = cluster.fit(features_std)\n",
    "\n",
    "# View predict class\n",
    "model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion:\n",
    "k-means clustering is one of the most common clustering techniques. In k-means clustering, the algorithm attempts to group observations into k groups, with each group having roughly equal variance. The number of groups, k, is specified by the user as a hyperparameter. Specifically, in k-means:\n",
    "\n",
    "1. k cluster \"center\" points are created at random locations.\n",
    "\n",
    "2. For each observation: \n",
    "    a. the distance between each observation and the k center points is calculated \n",
    "    b. the observation is assigned to the cluster of the nearest center point\n",
    "\n",
    "3. The center points are moved to the means (i.e., centers) of their respective clusters\n",
    "\n",
    "4. Steps 2 and 3 are repeated until no observation changes in cluster membership\n",
    "\n",
    "Three things to note about k-means:\n",
    "- k-means clustering assumes the clusters are convex shaped (e.g. a circle, a sphere).\n",
    "- all features are equally scaled (e.g. using a StandardScaler)\n",
    "- the groups are balanced (i.e., have roughly the same number of observations)\n",
    "\n",
    "In our solution, we cheated a little and used the Iris flower data, in which we know there are three classes. Therefore, we set k = 3. If we compare our results to the observationâ€™s true class we can see that despite the difference in class labels (i.e., 1, 2, and 3), k-means did reasonably well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View true class\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the trained cluster to predict the value of new observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new observation\n",
    "new_observation = [[0.8, 0.8, 0.8, 0.8]]\n",
    "\n",
    "# Predict observation's cluster\n",
    "model.predict(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observation is predicted to belong to the cluster whose center point is closest. We can even use cluster_centers_ to see those center points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.13597027,  0.08842168,  0.99615451,  1.01752612],\n",
       "       [-1.01457897,  0.85326268, -1.30498732, -1.25489349],\n",
       "       [-0.05021989, -0.88337647,  0.34773781,  0.2815273 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View cluster centers\n",
    "model.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.2 Speeding Up K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You want to group observations into k groups, but k-means takes too long.\n",
    "- Use **mini-batch k-means**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)\n",
    "\n",
    "# Create k-mean object\n",
    "cluster = MiniBatchKMeans(n_clusters=3, random_state=0, batch_size=100)\n",
    "\n",
    "# Train model\n",
    "model = cluster.fit(features_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
