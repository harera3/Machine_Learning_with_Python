{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAPTER 11\n",
    "---\n",
    "# MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- In this chapter we will examine strategies for evaluating the quality of models created through our learning algorithms. \n",
    "- It might appear strange to discuss model evaluation before discussing how to create them, but there is a method to our madness. \n",
    "- Models are only as useful as the quality of their predictions, and thus fundamentally our goal is not to create models (which is easy) but to create high-quality models (which is hard). \n",
    "- Therefore, before we explore the myriad learning algorithms, we first set up how we can evaluate the models they produce.\n",
    "\n",
    "## 11.1 Cross-Validating Models\n",
    "**Problem:** we want to evaluate how well our model will work in the real world\n",
    "\n",
    "**Solution:** we will create a pipeline that\n",
    "- preprocesses the data, \n",
    "- trains the model, and then \n",
    "- evaluates it using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9693916821849783"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# create features matrix\n",
    "features = digits.data\n",
    "\n",
    "# create target vector\n",
    "target = digits.target\n",
    "\n",
    "# create standardizer\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# create logitic regression object\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# create a pipeline that standardizes, then runs logistic regression\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "\n",
    "# create k-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# conduct k-fold cross-validation\n",
    "cv_results = cross_val_score(pipeline, # Pipeline\n",
    "                             features, # feature matrix\n",
    "                             target, # target vector\n",
    "                             cv=kf, # cross-validation technique,\n",
    "                             scoring=\"accuracy\", # loss function\n",
    "                             n_jobs=-1) # use all CPU cores\n",
    "\n",
    "# calculate mean\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "- Our goal is to evaluate how well our model does on data it has never seen before (e.g., a new customer, a new crime, a new image). \n",
    "- **The validation approach:**\n",
    "    - split data into training set and test set\n",
    "    - set the test set aside and pretend it's never been seen before\n",
    "    - train the model on the training set and teach it how to make the best predictions\n",
    "    - evaluate the model on the testing set and see how it does\n",
    "- The two major weaknesses of the validation approach:\n",
    "    - the performance of the model can be highly dependent on which few observations were selected for the test set. \n",
    "    - Second, the model is not being trained using all the available data, and not being evaluated on all the available data.\n",
    "- **The k-fold cross-validation (KFCV) strategy:**\n",
    "    - data is split into k parts, called \"*folds*\"\n",
    "    - the model is trained using k-1 folds, combined as a training set\n",
    "    - the last fold is used as a test set\n",
    "    - this is repeated k times each time using a different fold as the test set. \n",
    "    - The performance on the model for each of the k iterations is then averaged to produce an overall measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.98888889, 0.96111111, 0.94444444, 0.97777778,\n",
       "       0.98333333, 0.95555556, 0.98882682, 0.97765363, 0.93854749])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KFCV assumes that each observation was created independent from the other, if so it is a good idea to shuffle observations which can be done in scikit-learn by setting shuffle=True.\n",
    "- When using KFCV to evaluate a classifier, it is often beneficial to perform *stratified k-fold* by replacing KFold class with StratifiedKFold. \n",
    "- When using validation sets or cross-validation, it is important to preprocess data based on the training set and then apply those transformations to both the training and test set. The reason is\n",
    "    - we are pretending that the test set is unknown data\n",
    "    - it prevents the leaking of information from test set into the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.98888889, 0.96111111, 0.94444444, 0.97777778,\n",
       "       0.98333333, 0.95555556, 0.98882682, 0.97765363, 0.93854749])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# Fit standardizer to training set\n",
    "standardizer.fit(features_train)\n",
    "\n",
    "# Apply to both training and test sets\n",
    "features_train_std = standardizer.transform(features_train)\n",
    "features_test_std = standardizer.transform(features_test)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = make_pipeline(standardizer, logit)\n",
    "\n",
    "# Do k-fold cross-validation\n",
    "cv_results = cross_val_score(pipeline, # Pipeline\n",
    "                             features, # Feature matrix\n",
    "                             target, # Target vector\n",
    "                             cv=kf, # Cross-validation technique\n",
    "                             scoring=\"accuracy\", # Loss function\n",
    "                             n_jobs=-1) # Use all CPU scores\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross_val_score parameters:\n",
    "- cv determines our cross-validation technique. K-fold is the most common by far\n",
    "- the scoring parameter defines our metric for success\n",
    "- n_jobs=-1 tells scikit-learn to use every core of the computer available to speed up the operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Creating a Baseline Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** we want a simple baseline regression model to compare against our model.\n",
    "\n",
    "**Solution:** use scikit-learn’s DummyRegressor to create a simple model to use as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.001119359203955339"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "boston = load_boston()\n",
    "\n",
    "# Create features\n",
    "features, target = boston.data, boston.target\n",
    "\n",
    "# Make test and training split\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, random_state=0)\n",
    "\n",
    "# Create a dummy regressor\n",
    "dummy = DummyRegressor(strategy='mean')\n",
    "\n",
    "# \"Train\" dummy regressor\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "# Get R-squared score\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare, we train our model and evaluate the performance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6354638433202129"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train simple linear regression model\n",
    "ols = LinearRegression()\n",
    "ols.fit(features_train, target_train)\n",
    "\n",
    "# Get R-squared score\n",
    "ols.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 Creating a Baseline Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** You want a simple baseline classifier to compare against your model.\n",
    "\n",
    "**Solution:** Use scikit-learn’s DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42105263157894735"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "\n",
    "# Create target vector and feature matrix\n",
    "features, target = iris.data, iris.target\n",
    "\n",
    "# Split into training and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "features, target, random_state=0)\n",
    "\n",
    "# Create dummy classifier\n",
    "dummy = DummyClassifier(strategy='uniform', random_state=1)\n",
    "\n",
    "# \"Train\" model\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "# Get accuracy score\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the baseline classifier to our trained classifier, we can see the improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Train model\n",
    "classifier.fit(features_train, target_train)\n",
    "\n",
    "# Get accuracy score\n",
    "classifier.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A common measure of a classifier’s performance is how much better it is than random guessing. scikit-learn’s DummyClassifier makes this comparison easy. \n",
    "- The strategy parameter gives us a number of options for generating values. There are two strategies. \n",
    "    - *stratified* makes predictions that are proportional to the training set’s target vector’s class proportions \n",
    "    - *uniform* will generate predictions uniformly at random between the different classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 Evaluating Binary Classifier Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Given a trained classification model, you want to evaluate its quality.\n",
    "\n",
    "**Solution:** Use scikit-learn’s cross_val_score to conduct cross-validation while using the scoring parameter to define one of a number of performance metrics, including accuracy, precision, recall, and F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9555, 0.95  , 0.9585, 0.9555, 0.956 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# generate features matrix and target vector\n",
    "X, y = make_classification(n_samples = 10000,\n",
    "                           n_features = 3,\n",
    "                           n_informative = 3,\n",
    "                           n_redundant = 0,\n",
    "                           n_classes = 2,\n",
    "                           random_state = 1)\n",
    "# create logistic regression\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# cross-validate model using accuracy\n",
    "cross_val_score(logit, X, y, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95963673, 0.94820717, 0.9635996 , 0.96149949, 0.96060606])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using precision\n",
    "cross_val_score(logit, X, y, scoring=\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.951, 0.952, 0.953, 0.949, 0.951])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using recall\n",
    "cross_val_score(logit, X, y, scoring=\"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95529884, 0.9500998 , 0.95827049, 0.95520886, 0.95577889])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using f1\n",
    "cross_val_score(logit, X, y, scoring=\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can measure accuracy in 5-fold (the default number of folds) cross-validation by setting scoring=\"accuracy\"\n",
    "- Models with high precision are pessimistic in that they only predict an observation is of the positive class when they are very certain about it.\n",
    "- Models with high recall are optimistic in that they have a low bar for predicting that an observation is in the positive class\n",
    "- The F1 score is the harmonic mean (a kind of average used for ratios). It is a measure of correctness achieved in positive prediction—that is, of observations labeled as positive, how many are actually positive.\n",
    "\n",
    "Alternatively to using cross_val_score, if we already have the true y values and the predicted y values, we can calculate metrics like accuracy and recall directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.947"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create training and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "# Predict values for training target vector\n",
    "y_hat = logit.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5 Evaluating Binary Classifier Thresholds\n",
    "\n",
    "**Problem:** You want to evaluate a binary classifier and various probability thresholds.\n",
    "\n",
    "**Solution:** The Receiving Operating Characteristic (ROC) curve is a common method for evaluating the quality of a binary classifier. \n",
    "\n",
    "In scikit-learn, we can use roc_curve to calculate the true and false positives at each threshold, then plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# load libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create feature matrix and target vector\n",
    "features, target = make_classification(n_samples=10000,\n",
    "                                       n_features=10,\n",
    "                                       n_classes=2,\n",
    "                                       n_informative=3,\n",
    "                                       random_state=3)\n",
    "# split into training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=1)\n",
    "\n",
    "# create classifier\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# train model\n",
    "logit.fit(features_train, target_train)\n",
    "\n",
    "# get predicted probabilities\n",
    "target_probabilities = logit.predict_proba(features_test)[:,1]\n",
    "\n",
    "# create true and positive rates\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(target_test, target_probabilities)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.title(\"Reciever Operating Characteristic\")\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1,0], c=\".7\") \n",
    "plt.plot([1, 1], c=\".7\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROC compares the presence of true positives and false positives at every probability threshold (i.e., the probability at which an observation is predicted to be a class). \n",
    "- By plotting the ROC curve, we can see how the model performs. \n",
    "    - A classifier that predicts every observation correctly would look like the solid light gray line in the chart above, going straight up to the top immediately. \n",
    "    - A classifier that predicts at random will appear as the diagonal line. \n",
    "    - The better the model, the closer it is to the solid line.     \n",
    "\n",
    "#### Discussion:\n",
    "- Up until now we have only examined models based on the values they predict. \n",
    "- However, in many learning algorithms those predicted values are based off of probability estimates. \n",
    "- In our solution, we can use predict_proba to see the predicted probabilities for the first observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87094106, 0.12905894]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predicted probabilities\n",
    "logit.predict_proba(features_test)[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see the probability classes\n",
    "logit.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the first observation has an ~87% chance of being in the negative class (0) and a 13% chance of being in the positive class (1)\n",
    "\n",
    "**Threshold:** By default, scikit-learn predicts an observation is part of the positive class if the probability is greater than 0.5\n",
    "- However, instead of a middle ground, we will often want to explicitly bias our model to use a different threshold for substantive reasons: false positive or false negative, which one to avoid the most?\n",
    "- The prediction trade-off is represented by the true positive rate (TPR) and the false positive rate (FPR)\n",
    "- The ROC curve represents the respective TPR and FPR for every probability threshold. \n",
    "- Let's examine the threshold values and see what happens to TPR and FPR when we change the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52006024, 0.51901229, 0.51469154, 0.51464729, 0.51192875,\n",
       "       0.50977873, 0.50556537, 0.50265506, 0.50208102, 0.5016343 ,\n",
       "       0.50068825, 0.49922991, 0.49273392, 0.49237501, 0.49226661,\n",
       "       0.49224401, 0.49221264, 0.4882918 , 0.484656  , 0.48362505])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from Innocent, not in book\n",
    "threshold[240:260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2d5e5cd8bc8>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from Innocent, not in book\n",
    "# excluding the first value, which is 2\n",
    "plt.plot(threshold[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our solution a threshold of roughly 0.50 has a TPR of ~0.84 and an FPR of ~0.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5006882519902771\n",
      "True Positive Rate: 0.839518555667001\n",
      "False Positive Rate: 0.1744765702891326\n"
     ]
    }
   ],
   "source": [
    "print(\"Threshold: {}\".format(threshold[250]))\n",
    "print(\"True Positive Rate: {}\".format(true_positive_rate[250]))\n",
    "print(\"False Positive Rate: {}\".format(false_positive_rate[250]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we increase the threshold to ~80% (i.e., increase how certain the model has to be before it predicts an observation as positive) the TPR drops significantly but so does the FPR. This is because our higher requirement for being predicted to be in the positive class has made the model not identify a number of positive observations (the lower TPR), but also reduce the noise from negative observations being predicted as positive (the lower FPR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.8043803686853731\n",
      "True Positive Rate: 0.567703109327984\n",
      "False Positive Rate: 0.05284147557328016\n"
     ]
    }
   ],
   "source": [
    "print(\"Threshold: {}\".format(threshold[95]))\n",
    "print(\"True Positive Rate: {}\".format(true_positive_rate[95]))\n",
    "print(\"False Positive Rate: {}\".format(false_positive_rate[95]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often common to calculate the area under the ROC curve (AUCROC) to judge the overall quality of a model at all possible thresholds. The better a model is, the higher the curve and thus the greater the area under the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9060171541543875"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate area under curve\n",
    "roc_auc_score(target_test, target_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.6 Evaluating Multiclass Classifier Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** You have a model that predicts three or more classes and want to evaluate its performance.\n",
    "\n",
    "**Solution:** Use cross-validation with an evaluation metric capable of handling more than two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.841 , 0.829 , 0.8265, 0.8155, 0.82  ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# generate features matrix and target vector\n",
    "features, target = make_classification(n_samples=10000,\n",
    "                                       n_features=3,\n",
    "                                       n_informative=3,\n",
    "                                       n_redundant=0,\n",
    "                                       n_classes=3,\n",
    "                                       random_state=1)\n",
    "# create logistic regression\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# cross-validate model using accuracy\n",
    "cross_val_score(logit, features, target, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion:\n",
    "- When we have balanced classes (e.g. a roughly equal number of observations in each class of a target vector), accuracy is--just like in the binary class setting--a simple and interpretable choce for an evaluation metric. \n",
    "    - Accuracy is the number of correct predictions divided by the number of observations and works just as well in the multiclass as binary setting. \n",
    "- However, when we have imbalanced classes (a common scenario), we should be inclined to use other evaluation metrics.\n",
    "    - Precision, recall, and F1 scores are useful metrics. \n",
    "    - While all of them were originally designed for binary classifiers, we can apply them to multiclass settings by treating our data as a set of binary classes. \n",
    "    - Doing so enables us to apply the metrics to each class as if it were the only class in the data, and then aggregate the evaluation scores for all the classes by averaging them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84061272, 0.82895312, 0.82625661, 0.81515121, 0.81992692])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using macro averaged F1 score\n",
    "cross_val_score(logit, features, target, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods used to average the evaluation scores from the classes:\n",
    "- **macro:** Calculate mean of metric scores for each class, weighting each class equally.\n",
    "- **weighted:** Calculate mean of metric scores for each class, weighting each class proportional to its size in the data.\n",
    "- **micro:** Calculate mean of metric scores for each observation-class combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84063166, 0.8289688 , 0.82630601, 0.8151928 , 0.81998327])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using macro averaged F1 score\n",
    "cross_val_score(logit, features, target, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.841 , 0.829 , 0.8265, 0.8155, 0.82  ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validate model using macro averaged F1 score\n",
    "cross_val_score(logit, features, target, scoring='f1_micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.7 Visualizing a Classifier’s Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Given predicted classes and true classes of the test data, you want to visually compare the model’s quality.\n",
    "\n",
    "**Solution:** Use a confusion matrix, which compares predicted classes and true classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# create feature matrix\n",
    "features = iris.data\n",
    "\n",
    "# create target vector\n",
    "target = iris.target\n",
    "\n",
    "# create list of target class names\n",
    "class_names = iris.target_names\n",
    "\n",
    "# split into training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=1)\n",
    "\n",
    "# create logistic regression\n",
    "classifier = LogisticRegression(max_iter=200)\n",
    "\n",
    "# train model and make predictions\n",
    "target_predicted = classifier.fit(features_train, target_train).predict(features_test)\n",
    "\n",
    "# create confusion matrix\n",
    "matrix = confusion_matrix(target_test, target_predicted)\n",
    "\n",
    "# create pandas dataframe\n",
    "dataframe = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# create heatmap\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\") \n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"True Class\") \n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion:\n",
    "- Confusion matrices are an easy, effective visualization of a classifier’s performance.\n",
    "- One of the major benefits of confusion matrices is their interpretability. \n",
    "    - Each column of the matrix (often visualized as a heatmap) represents predicted classes, while every row shows true classes. \n",
    "    - The end result is that every cell is one possible combination of predict and true classes. \n",
    "- This is probably best explained using an example. \n",
    "    - In the solution, the top-left cell is the number of observations predicted to be Iris setosa (indicated by the column) that are actually Iris setosa (indicated by the row)\n",
    "    \n",
    "There are three things worth noting about confusion matrices. \n",
    "- First, a perfect model will have values along the diagonal and zeros everywhere else. \n",
    "    - A bad model will look like the observation counts will be spread evenly around cells. \n",
    "- Second, a confusion matrix lets us see not only where the model was wrong, but also how it was wrong.\n",
    "    - That is, we can look at patterns of misclassification. \n",
    "- Finally, confusion matrices work with any number of classes (although if we had one million classes in our target vector, the confusion matrix visualization might be difficult to read)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.8 Evaluating Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:**  You want to evaluate the performance of a regression model.\n",
    "\n",
    "**Solution:** Use mean squared error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1974.65337976, -2004.54137625, -3935.19355723, -1060.04361386,\n",
       "       -1598.74104702])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# generate features matrix, target vector\n",
    "features, target = make_regression(n_samples = 100,\n",
    "                                   n_features = 3,\n",
    "                                   n_informative = 3,\n",
    "                                   n_targets = 1,\n",
    "                                   noise = 50,\n",
    "                                   coef = False,\n",
    "                                   random_state = 1)\n",
    "# create a linear regression object\n",
    "ols = LinearRegression()\n",
    "\n",
    "# cross-validate the lienar regression using (negative) MSE\n",
    "cross_val_score(ols, features, target, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8622399 , 0.85838075, 0.74723548, 0.91354743, 0.84469331])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validate the linear regression using R-squared\n",
    "cross_val_score(ols, features, target, scoring='r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion:\n",
    "- MSE is a measurement of the squared sum of all distances between predicted and true values.\n",
    "    - The higher the value of MSE, the greater the total squared error and thus the worse the model. \n",
    "- Mathematical benefits to squaring the error term \n",
    "    - it forces all error values to be positive \n",
    "    - it penalizes a few large errors more than many small errors, even if the absolute value of the errors is the same. \n",
    "- Scikit-Learn arguments of the scoring parameter assume that higher values are better than lower values. \n",
    "    - However, this is not the case for MSE, where higher values mean a worse model. \n",
    "    - For this reason, scikit-learn looks at the negative MSE using the neg_mean_squared_error argument.\n",
    "- A common alternative regression evaluation metric is $R^2$ (the coefficient of determination), which measures the amount of variance in the target vector that is explained by the model\n",
    "    - The closer to 1.0, the better the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.9 Evaluating Clustering Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** You have used an unsupervised learning algorithm to cluster your data. Now you want to know how well it did.\n",
    "\n",
    "**Solution:** The short answer is that you probably can’t, at least not in the way you want. That said, one option is to evaluate clustering using silhouette coefficients, which measure the quality of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8916265564072142"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# generate feature matrix\n",
    "features, _ = make_blobs(n_samples = 1000,\n",
    "                         n_features = 10,\n",
    "                         centers = 2,\n",
    "                         cluster_std = 0.5,\n",
    "                         shuffle = True,\n",
    "                         random_state = 1)\n",
    "\n",
    "# cluster data using k-means to predict classes\n",
    "model = KMeans(n_clusters=2, random_state=1).fit(features)\n",
    "\n",
    "# get predicted classes\n",
    "target_predicted = model.labels_\n",
    "\n",
    "# evaluate model\n",
    "silhouette_score(features, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion:\n",
    "- We cannot evaluate predictions versus true values if we don't have a target vector, but we can evaluate the nature of the clusters themselves. \n",
    "- Intuitively, we can imagine \"good\" clusters having very small distances between the different clusters (i.e., well separated clusters). \n",
    "- Silhouette coefficients provide a single value measuring both traits. Formally, the ith observation's silhouette coefficient is:\n",
    "\n",
    "$$\n",
    "s_i = \\frac{b_i - a}{max(a_i, b_i)}\n",
    "$$\n",
    "\n",
    "$s_i$ is the silhouette coefficient for observation i, $a_i$ is the mean distance between i and all observations of the same class, $b_i$ is the mean distance between i and all observations of a different class\n",
    "- Silhouette coefficients range between -1 and 1, with 1 indicating dense, well-separated clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.10 Creating a Custom Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** You want to evaluate a model using a metric you created.\n",
    "\n",
    "**Solution:** Create the metric as a function and convert it into a scorer function using scikit-learn’s *make_scorer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997906102882058"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Generate features matrix and target vector\n",
    "features, target = make_regression(n_samples = 100,\n",
    "                                   n_features = 3,\n",
    "                                   random_state = 1)\n",
    "\n",
    "# Create training set and test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "     features, target, test_size=0.10, random_state=1)\n",
    "\n",
    "# Create custom metric\n",
    "def custom_metric(target_test, target_predicted):\n",
    "    # Calculate r-squared score\n",
    "    r2 = r2_score(target_test, target_predicted)\n",
    "    # Return r-squared score\n",
    "    return r2\n",
    "\n",
    "# Make scorer and define that higher scores are better\n",
    "score = make_scorer(custom_metric, greater_is_better=True)\n",
    "\n",
    "# Create ridge regression object\n",
    "classifier = Ridge()\n",
    "\n",
    "# Train ridge regression model\n",
    "model = classifier.fit(features_train, target_train)\n",
    "\n",
    "# Apply custom scorer\n",
    "score(model, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The custom metric in the solution (custom_metric) is a toy example since it simply wraps a built-in metric for calculating the R2 score. \n",
    "- In a real-world situation, we would replace the custom_metric function with whatever custom metric we wanted.\n",
    "- However, we can see that the custom metric that calculates R2 does work by comparing the results to scikit-learn’s r2_score built-in method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997906102882058"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict values\n",
    "target_predicted = model.predict(features_test)\n",
    "\n",
    "# Calculate r-squared score\n",
    "r2_score(target_test, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.11 Visualizing the Effect of Training Set Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** You want to evaluate the effect of the number of observations in your training set on some metric (accuracy, F1, etc.)\n",
    "\n",
    "**Solution:** Plot the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
