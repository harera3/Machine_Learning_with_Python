{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAPTER 4 \n",
    "---\n",
    "# HANDLING NUMERICAL  DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.1 Rescaling a Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load NumPy library\n",
    "- Load 'preprocessing' from 'sklearn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a NumPy array (feature named 'array_1') containing: -500.5, -100.1, 0, 100.1, 900.9\n",
    "- Show 'array_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-500.5],\n",
       "       [-100.1],\n",
       "       [   0. ],\n",
       "       [ 100.1],\n",
       "       [ 900.9]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_1 = np.array([[-500.5], [-100.1], [0], [100.1], [900.9]])\n",
    "array_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a 'MinMaxScaler' (named 'minmax_scaler') with a range of 0-1\n",
    "- Show 'minmax_scaler'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "minmax_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use 'minmax_scaler' to scale 'array_1' and name it 'array_1_scaled'\n",
    "- Show 'array_1_scaled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_1_scaled = minmax_scaler.fit_transform(array_1)\n",
    "array_1_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a 'MinMaxScaler' (named 'minmax_scaler_2') with a range of 0-5\n",
    "- Use 'minmax_scaler_2' to scale 'array_1' and name it 'array_1_scaled_2'\n",
    "- Show 'array_1_scaled_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [1.42857143],\n",
       "       [1.78571429],\n",
       "       [2.14285714],\n",
       "       [5.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_scaler_2 = preprocessing.MinMaxScaler(feature_range=(0,5))\n",
    "array_1_scaled_2 = minmax_scaler_2.fit_transform(array_1)\n",
    "array_1_scaled_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a 'MinMaxScaler' (named 'minmax_scaler_3') with a range of -5 to 5\n",
    "- Use 'minmax_scaler_3' to scale 'array_1' and name it 'array_1_scaled_3'\n",
    "- Show 'array_1_scaled_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.        ],\n",
       "       [-2.14285714],\n",
       "       [-1.42857143],\n",
       "       [-0.71428571],\n",
       "       [ 5.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_scaler_3 = preprocessing.MinMaxScaler(feature_range=(-5,5))\n",
    "array_1_scaled_3 = minmax_scaler_3.fit_transform(array_1)\n",
    "array_1_scaled_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MinMaxScaler Formula:**\n",
    "$$\n",
    "x_i^` = \\frac{x_i - min(x)}{max(x) - min(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Standardizing a Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a NumPy array (feature named 'array_2') containing: -1000.1, -200.2, 500.5, 600.6, 9000.9\n",
    "- Show 'array_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1000.1],\n",
       "       [ -200.2],\n",
       "       [  500.5],\n",
       "       [  600.6],\n",
       "       [ 9000.9]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_2 = np.array([[-1000.1], [-200.2], [500.5], [600.6], [9000.9]])\n",
    "array_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a 'StandardScaler' named 'std_scaler'\n",
    "- Show 'minmax_scaler'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scaler = preprocessing.StandardScaler()\n",
    "std_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standardize 'array_2' and name it 'array_2_stdized'\n",
    "- Show 'array_2_stdized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76058269],\n",
       "       [-0.54177196],\n",
       "       [-0.35009716],\n",
       "       [-0.32271504],\n",
       "       [ 1.97516685]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_2_stdized = std_scaler.fit_transform(array_2)\n",
    "array_2_stdized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the rounded mean of 'array_2'\n",
    "- Print the rounded mean of 'array_2_stdized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(round(array_2.mean()))\n",
    "print(round(array_2_stdized.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the rounded standard deviation of 'array_2'\n",
    "- Print the rounded standard deviation of 'array_2_stdized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3656\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(round(array_2.std()))\n",
    "print(round(array_2_stdized.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**StandardScaler Formula:**\n",
    "$$\n",
    "x_i^` = \\frac{x_i - \\bar x}{\\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Normalizing Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import 'Normalizer' from sklearn preprocessing\n",
    "- Create a 2d array ('array_3') containing: 0.5, 0.5; 1.1, 3.4; 1.5, 20.2; 1.63, 34.4; and 10.9, 3.3\n",
    "- Create a normalizer ('norm_l2') with 'norm=l2'\n",
    "- Normalize 'array_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "array_3 = np.array([\n",
    "                    [0.5, 0.5],\n",
    "                    [1.1, 3.4],\n",
    "                    [1.5, 20.2],\n",
    "                    [1.63, 34.4],\n",
    "                    [10.9, 3.3]\n",
    "                ])\n",
    "norm_l2 = Normalizer(norm=\"l2\")\n",
    "norm_l2.transform(array_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a normalizer with 'norm=l2' and normalize 'array_3' in one step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Normalizer(norm=\"l2\").transform(array_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a normalizer with 'norm=l1' and normalize 'array_3' in one step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.24444444, 0.75555556],\n",
       "       [0.06912442, 0.93087558],\n",
       "       [0.04524008, 0.95475992],\n",
       "       [0.76760563, 0.23239437]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Normalizer(norm=\"l1\").transform(array_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Intuitively, L2 norm can be thought of as the distance between two points in New York for a bird (i.e., a straight line), while L1 can be thought of as the distance for a human walking on the street (walk north one block, east one block, north one block, east one block, etc.), which is why it is called “Manhattan norm” or “Taxicab norm.” Practically, notice that norm='l1' rescales an observation’s values so they sum to 1, which can sometimes be a desirable quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Transforming Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import 'FunctionTransformer' from 'sklearn preprocessing'\n",
    "- Create a 2d array ('array_4') containing: 2, 3; 2, 3; and 2, 3\n",
    "- Define a simple function ('add_10') that takes in one argument ('x') and returns 'x+10'\n",
    "- Create a transformer, 'ten_transformer'\n",
    "- Transform 'array_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 13],\n",
       "       [12, 13],\n",
       "       [12, 13]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "array_4 = np.array([[2, 3], [2, 3], [2, 3]])\n",
    "\n",
    "def add_10(x):\n",
    "    return x + 10\n",
    "\n",
    "ten_transformer = FunctionTransformer(add_10)\n",
    "ten_transformer.transform(array_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import Pandas\n",
    "- Create a dataframe ('array_4_df') from 'array_4' with 'col1' and 'col2' as columns \n",
    "- Apply 'add_10' function to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "0    12    13\n",
       "1    12    13\n",
       "2    12    13"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "array_4_df = pd.DataFrame(array_4, columns=['col1', 'col2'])\n",
    "array_4_df.apply(add_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Deleting Observations with Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a 2d array ('array_5') containing: 1.1, 11.1; 2.2, 22.2; 3.3, 33.3; 4.4, 44.4; np.nan, 55\n",
    "- Keep only observations that are not missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1, 11.1],\n",
       "       [ 2.2, 22.2],\n",
       "       [ 3.3, 33.3],\n",
       "       [ 4.4, 44.4]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_5 = np.array([[1.1, 11.1], [2.2, 22.2], [3.3, 33.3], [4.4, 44.4], [np.nan, 55]])\n",
    "array_5[~np.isnan(array_5).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a dataframe ('array_5_df') from 'array_5' with 'col1' and 'col2' as columns\n",
    "- Remove observations with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>44.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "0   1.1  11.1\n",
       "1   2.2  22.2\n",
       "2   3.3  33.3\n",
       "3   4.4  44.4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_5_df = pd.DataFrame(array_5, columns=['col1', 'col2'])\n",
    "array_5_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Imputing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import 'StandardScaler' from 'sklearn.preprocessing'\n",
    "- Import 'make_blobs' from 'sklearn.datasets'\n",
    "- Import 'SimpleImputer' from 'sklearn.impute'\n",
    "- Make fake data ('fake, blobs') from 'make_blobs' with 1000 samples, 2 features, and a random state of 1\n",
    "- Show the first 5 rows of 'fake,blobs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-3.05837272,  4.48825769],\n",
       "        [-8.60973869, -3.72714879],\n",
       "        [ 1.37129721,  5.23107449],\n",
       "        [-9.33917563, -2.9544469 ],\n",
       "        [-8.63895561, -8.05263469]]),\n",
       " array([0, 1, 0, 1, 2]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "fake,blobs = make_blobs(n_samples = 1000,\n",
    "                        n_features = 2,\n",
    "                        random_state = 1)\n",
    "fake[:5],blobs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standardize the data and name it 'standardized_blobs'\n",
    "- Assign the first value of 'standardized_blobs' to a variable named 'true_value'\n",
    "- Show the first 3 rows of 'standardized_blobs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87301861,  1.31426523],\n",
       "       [-0.67073178, -0.22369263],\n",
       "       [ 2.1048424 ,  1.45332359]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_blobs = StandardScaler().fit_transform(fake,blobs)\n",
    "true_value = standardized_blobs[0, 0]\n",
    "standardized_blobs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assign the first value of 'standardized_blobs' to 'np.nan'\n",
    "- Show the first 3 rows of 'standardized_blobs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        nan,  1.31426523],\n",
       "       [-0.67073178, -0.22369263],\n",
       "       [ 2.1048424 ,  1.45332359]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_blobs[0,0] = np.nan\n",
    "standardized_blobs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a mean imputer named 'mean_imputer'\n",
    "- Impute 'fake,blobs' and call it 'blob_imputed'\n",
    "- Using format function, print \"True Value\" and 'true_value'\n",
    "- Using format function, print \"Imputed Value\" and 'blob_imputed' at 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 0.8730186113995938\n",
      "Imputed Value: -3.058372724614996\n"
     ]
    }
   ],
   "source": [
    "mean_imputer = SimpleImputer(strategy=\"mean\")\n",
    "blob_imputed = mean_imputer.fit_transform(fake,blobs)\n",
    "\n",
    "print(\"True Value: {}\".format(true_value))\n",
    "print(\"Imputed Value: {}\".format(blob_imputed[0,0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
